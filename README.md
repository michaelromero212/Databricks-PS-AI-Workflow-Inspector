# Databricks PS AI Workflow Inspector

![Status](https://img.shields.io/badge/Status-Production%20Ready-blue)
![Tech](https://img.shields.io/badge/Tech-FastAPI%20%7C%20JavaScript%20%7C%20Databricks%20CLI-orange)

---

## ğŸ¯ Problem Statement

**For Databricks Professional Services Teams:**

During client engagements, PS consultants often encounter production workflows with:
- âŒ Inefficient cluster configurations costing thousands in unnecessary compute
- âŒ Undocumented notebooks making maintenance difficult
- âŒ Poor code quality leading to pipeline failures
- âŒ Security vulnerabilities (hardcoded credentials, missing error handling)

**Manual code reviews are time-consuming and inconsistent.** This tool automates the entire workflow inspection process using **AI-powered analysis** to deliver instant, **actionable insights** and **cost optimization recommendations**.

---

## ğŸ“¸ Dashboard Overview

### Main Interface
The dashboard provides an intuitive interface for selecting and scanning Databricks workflows:

![Dashboard Main](assets/images/dashboard_main.jpg)

### Job Selection
Connect to a client's Databricks workspace and select any workflow for analysis:

![Job Selection](assets/images/job_selected.jpg)

### Comprehensive Analysis Results
Instant, AI-powered insights with:
- **Health Scores**: 0-100 ratings for Workflow Health, Code Quality, and Documentation
- **Top Fixes**: Prioritized, actionable recommendations
- **Cluster Sizing**: Right-sizing suggestions to reduce costs
- **Detailed Issues**: Categorized findings with severity levels

![Analysis Results](assets/images/analysis_results.jpg)

### Workflow Dropdown
Easily browse all workflows in the connected workspace:

![Workflow Selection](assets/images/dashboard_selection.jpg)

---

## ğŸš€ Key Features

### AI-Powered Analysis
- **Notebook Quality Assessment**: Evaluates Python/SQL code against best practices
- **Documentation Completeness**: Scores inline comments and documentation
- **Security Scanning**: Identifies hardcoded credentials, missing error handling
- **Performance Optimization**: Suggests cluster sizing improvements

### Real-Time Insights
- **Instant Scoring**: 0-100 health scores across multiple dimensions
- **Prioritized Fixes**: Top 5 actionable recommendations
- **Detailed Reports**: Comprehensive breakdown of all issues

### Professional Services Value
- **Faster Engagements**: Reduce manual code review time from days to minutes
- **Data-Driven Recommendations**: Objective, AI-backed insights
- **Client-Ready Reports**: Professional PDF reports for stakeholder presentations

---

## ğŸ§° Tech Stack

### Backend
- **FastAPI** (Python 3.8+) - High-performance async web framework
- **Databricks CLI** - Direct integration with client workspaces
- **LLM Integration**: 
  - HuggingFace Inference API (Mistral-7B-Instruct)
  - Databricks Model Serving (DBRX)

### Frontend
- **Vanilla JavaScript** - No framework dependencies, lightweight and fast
- **Modern CSS3** - Professional, colorblind-safe design system
- **Responsive Design** - Works across desktop, tablet, and mobile

### Infrastructure
- **Uvicorn** ASGI server
- **Python venv** for dependency isolation
- **RESTful API** architecture

---

## ğŸ Quick Start

### Prerequisites
1. **Python 3.8+**
2. **Databricks CLI** installed and configured
   ```bash
   databricks configure
   ```
3. **(Optional) LLM API Access**:
   - HuggingFace token in `.env` file, OR
   - Databricks Model Serving endpoint

### Running the Application

1. **Clone the repository**
   ```bash
   cd databricks-ps-workflow-inspector
   ```

2. **Configure environment**
   ```bash
   cp .env.sample .env
   # Edit .env with your credentials
   ```

3. **Launch the application**
   ```bash
   ./start.sh
   ```
   This script automatically:
   - Creates a virtual environment
   - Installs all dependencies
   - Starts the FastAPI server

4. **Access the dashboard**
   Open your browser to **http://localhost:8000**

---

## ğŸ“‚ Project Structure

```
databricks-ps-workflow-inspector/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # FastAPI routes and endpoints
â”‚   â”œâ”€â”€ dbx_client.py           # Databricks CLI wrapper
â”‚   â”œâ”€â”€ analyzer.py             # AI-powered workflow analysis
â”‚   â”œâ”€â”€ model_selector.py       # LLM provider interface
â”‚   â””â”€â”€ report_generator.py     # Markdown/PDF report generation
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # Main UI structure
â”‚   â”œâ”€â”€ app.js                  # Application logic
â”‚   â”œâ”€â”€ styles.css              # Professional design system
â”‚   â””â”€â”€ colorblind_palette.js   # Accessible color schemes
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ images/                 # Dashboard screenshots
â”œâ”€â”€ outputs/                    # Generated reports and logs
â”œâ”€â”€ .env.sample                 # Environment configuration template
â””â”€â”€ start.sh                    # One-command startup script
```

---

## ğŸ—ï¸ Architecture

### System Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Frontend (Browser)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  index.html    â”‚  â”‚   app.js     â”‚  â”‚   styles.css    â”‚ â”‚
â”‚  â”‚  (UI Layout)   â”‚  â”‚  (Logic)     â”‚  â”‚  (Styling)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/REST
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Backend (Python)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  app.py (API Endpoints)                              â”‚   â”‚
â”‚  â”‚  â€¢ GET /jobs       â€¢ GET /status                     â”‚   â”‚
â”‚  â”‚  â€¢ POST /scan/{id} â€¢ GET /report/{id}/pdf            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  dbx_client.py â”‚  â”‚  analyzer.py    â”‚  â”‚ model_       â”‚ â”‚
â”‚  â”‚  (Databricks   â”‚  â”‚  (Workflow      â”‚  â”‚ selector.py  â”‚ â”‚
â”‚  â”‚   CLI Wrapper) â”‚  â”‚   Analysis)     â”‚  â”‚ (LLM API)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                     â”‚                    â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  report_generator.py (Markdown + PDF)                   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                         â”‚
           â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Databricks CLI     â”‚                   â”‚  LLM Provider    â”‚
â”‚  â€¢ Job Metadata     â”‚                   â”‚  â€¢ HuggingFace   â”‚
â”‚  â€¢ Notebook Source  â”‚                   â”‚  â€¢ Databricks    â”‚
â”‚  â€¢ Run History      â”‚                   â”‚    Serving       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow
1. **User Selection**: Select a workflow from the connected Databricks workspace
2. **Job Retrieval**: Backend fetches job configuration and notebook source via Databricks CLI
3. **AI Analysis**: Notebook code is analyzed by LLM for quality, security, and optimization opportunities
4. **Report Generation**: Results compiled into actionable insights and professional reports
5. **Display**: Frontend presents scores, recommendations, and detailed findings

---

## ğŸ§ª Testing the Application

### Demo Mode
The application works without a live Databricks workspace for demonstration purposes:

1. Launch the application: `./start.sh`
2. Open http://localhost:8000
3. Select a workflow (real or demo scenario)
4. Click **"Run Workflow Scan"**
5. Review the analysis results
6. Download the PDF report

### Production Use
1. Configure `.env` with Databricks workspace credentials
2. Ensure Databricks CLI is authenticated: `databricks jobs list`
3. Select real production workflows from the dropdown
4. Analyze and generate reports for client presentations

---

## ğŸ›¡ï¸ Security Notes

- All credentials stored in `.env` file (never committed to Git)
- `.gitignore` configured to protect sensitive files
- Databricks CLI authentication uses secure token-based auth
- No hardcoded credentials in source code

---

## ğŸ’¼ Professional Services Use Cases

### Engagement Kickoff
- Quickly assess client's existing workflows
- Identify immediate optimization opportunities
- Build credibility with data-driven insights

### Migration Projects
- Evaluate legacy code quality before migration
- Prioritize refactoring efforts
- Estimate cost savings from optimization

### Health Checks
- Regular workflow audits for existing clients
- Track improvements over time
- Demonstrate ongoing value

---

*Built for the Databricks Professional Services Team | Production-Ready Tool for Client Engagements*
